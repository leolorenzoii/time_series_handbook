{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f1c87c",
   "metadata": {},
   "source": [
    "# PhDinDS2024: Level 9 LightGBM (GOSS-regression) Middle Out Reconcilation\n",
    "\n",
    "This notebook presents a non-parametric ML approach to forecasting the last `28 days` of the M5 dataset. Specifically, a 28-step forecasting approach was done using a Multi-output LGBM Regressor.\n",
    "\n",
    "A LightGBM model was trained for each *Level 9 (store-department)* series totalling to 70 trained models for the base level forecasts. Both the input structure and ML parameters for was optimized for each series. Specifically, lookback window, and delay were both optimized in addition to choosing whether to use a lookback on endogenous (unit sales), lookback on exogenous (calendar, sell prices, promotions, holiday data), and lookahead on the same exogenous variables. Simultaneously, LighGBM parameters on a `goss` boosting method: `top_rate`, `other_rate`, `tree_learner`, `n_estimators`, `learning_rate`, and `num_leaves` were optimized for `rmse` on a `regression` objective. No early stopping was empoyed. *Reconciliation*: These Level 9 forecasts were then used to obtain Levels 1 to 8 using bottom-up (bu) reconciliation and to obtain Levels 10 to 12 using top-down (td, based on average proportions). For details see, `phdinds2024_entry/phdinds2024_entry.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43bddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:39.661207Z",
     "start_time": "2022-01-03T23:54:39.355670Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6949d14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:39.747377Z",
     "start_time": "2022-01-03T23:54:39.711107Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import PATHS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "__author__ = \"PhDinDS2024_Mike\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bdc29b",
   "metadata": {},
   "source": [
    "## Read\n",
    "\n",
    "The following contains sales data from day `d_1` to day `d_1941`. In the M5 competition, days `d_1914` to `d_1941` was used as a preliminary evaluation set and the consequent days `d_1942` to `d_1969` was used as the actual test set to rank the models for awarding. The approach that follows skips the preliminary evaluation and utilizes the entire train-eval set to tune a model that minimizes the WRMSSE on the actual test set: `d_1942` to `d_1969`. The evaluation on the test set follows in later presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2a0daf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:44.363357Z",
     "start_time": "2022-01-03T23:54:39.750128Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATHS.train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c0d2807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:44.417385Z",
     "start_time": "2022-01-03T23:54:44.365814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id    dept_id   cat_id store_id state_id  d_1  d_2  d_3  d_4  \\\n",
       "0  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "2  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "\n",
       "   d_5  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  d_1939  \\\n",
       "0    0  ...       2       4       0       0       0       0       3       3   \n",
       "1    0  ...       0       1       2       1       1       0       0       0   \n",
       "2    0  ...       1       0       2       0       0       0       2       3   \n",
       "\n",
       "   d_1940  d_1941  \n",
       "0       0       1  \n",
       "1       0       0  \n",
       "2       0       1  \n",
       "\n",
       "[3 rows x 1946 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05fb007a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:44.448743Z",
     "start_time": "2022-01-03T23:54:44.419427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d_1941'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns[-1] # confirm that we are indeed getting the entire train-val set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a60b7766",
   "metadata": {},
   "source": [
    "We see from the above examination that columns `item_id`, `dept_id`, `cat_id`, `store_id`, and `state_id` facilitate the aggregation of the data in the hierarchies shown in Figure 1. (lifted from the M5 presentation by Makridakis and Spiliotis).\n",
    "\n",
    "<img src=\"../../media/hierarchical_image1.JPG\" alt=\"M5 hierarchy\">\n",
    "<center><b>Figure 1.</b> An illustration of the hierarchies in the dataset. Aggregation and the subsequent top-down and bottom-up approaches are facilitated by the presented hierarchy</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b333f",
   "metadata": {},
   "source": [
    "Given the above scenario, the chosen approach is a middle-out approach for reasons that forecasting at higher level ids will require tuning thousands of models and forecasting at lower level ids may result to more errors during the disaggregation to get the higher level id forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a471fe45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:54:45.262491Z",
     "start_time": "2022-01-03T23:54:44.452095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_id  dept_id    \n",
      "CA_1      FOODS_1        False\n",
      "          FOODS_2        False\n",
      "          FOODS_3        False\n",
      "          HOBBIES_1      False\n",
      "          HOBBIES_2      False\n",
      "                         ...  \n",
      "WI_3      FOODS_3        False\n",
      "          HOBBIES_1      False\n",
      "          HOBBIES_2      False\n",
      "          HOUSEHOLD_1    False\n",
      "          HOUSEHOLD_2    False\n",
      "Length: 70, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>store_id</th>\n",
       "      <th colspan=\"7\" halign=\"left\">CA_1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CA_2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WI_2</th>\n",
       "      <th colspan=\"7\" halign=\"left\">WI_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept_id</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <th>FOODS_2</th>\n",
       "      <th>FOODS_3</th>\n",
       "      <th>HOBBIES_1</th>\n",
       "      <th>HOBBIES_2</th>\n",
       "      <th>HOUSEHOLD_1</th>\n",
       "      <th>HOUSEHOLD_2</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <th>FOODS_2</th>\n",
       "      <th>FOODS_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HOBBIES_2</th>\n",
       "      <th>HOUSEHOLD_1</th>\n",
       "      <th>HOUSEHOLD_2</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <th>FOODS_2</th>\n",
       "      <th>FOODS_3</th>\n",
       "      <th>HOBBIES_1</th>\n",
       "      <th>HOBBIES_2</th>\n",
       "      <th>HOUSEHOLD_1</th>\n",
       "      <th>HOUSEHOLD_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>297.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2293.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>284.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>214.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>175.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>182.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>151.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "store_id      CA_1                                                  \\\n",
       "dept_id    FOODS_1 FOODS_2 FOODS_3 HOBBIES_1 HOBBIES_2 HOUSEHOLD_1   \n",
       "2011-01-29   297.0   674.0  2268.0     528.0      28.0       361.0   \n",
       "2011-01-30   284.0   655.0  2198.0     489.0       9.0       350.0   \n",
       "2011-01-31   214.0   396.0  1398.0     409.0       6.0       279.0   \n",
       "2011-02-01   175.0   476.0  1607.0     383.0       9.0       278.0   \n",
       "2011-02-02   182.0   354.0  1496.0     263.0       5.0       195.0   \n",
       "\n",
       "store_id                  CA_2                  ...      WI_2              \\\n",
       "dept_id    HOUSEHOLD_2 FOODS_1 FOODS_2 FOODS_3  ... HOBBIES_2 HOUSEHOLD_1   \n",
       "2011-01-29       181.0   406.0   212.0  1575.0  ...      10.0       353.0   \n",
       "2011-01-30       170.0   408.0   227.0  1286.0  ...       7.0       268.0   \n",
       "2011-01-31       114.0   238.0   138.0   913.0  ...      18.0       250.0   \n",
       "2011-02-01       123.0   240.0   174.0  1126.0  ...      15.0       305.0   \n",
       "2011-02-02       135.0   220.0   102.0   956.0  ...      10.5       118.0   \n",
       "\n",
       "store_id                  WI_3                                      \\\n",
       "dept_id    HOUSEHOLD_2 FOODS_1 FOODS_2 FOODS_3 HOBBIES_1 HOBBIES_2   \n",
       "2011-01-29        98.0   152.0   583.0  2293.0     256.0      22.0   \n",
       "2011-01-30        94.0   138.0   585.0  2383.0     342.0      14.0   \n",
       "2011-01-31        69.0   127.0   575.0  1841.0     228.0      20.0   \n",
       "2011-02-01        80.0    98.0   533.0  1965.0     183.0      11.0   \n",
       "2011-02-02        32.0    87.0   340.0  1427.0      70.0       9.5   \n",
       "\n",
       "store_id                            \n",
       "dept_id    HOUSEHOLD_1 HOUSEHOLD_2  \n",
       "2011-01-29       584.0       148.0  \n",
       "2011-01-30       541.0       195.0  \n",
       "2011-01-31       420.0       106.0  \n",
       "2011-02-01       327.0        94.0  \n",
       "2011-02-02       151.0        53.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate to level 9 store-department\n",
    "train = train.groupby(['store_id', 'dept_id']).sum().T\n",
    "train.index = pd.date_range(start='2011-01-29', end='2016-05-22', freq='D')\n",
    "train[train < 5] = np.nan\n",
    "train = train.interpolate(method='linear')\n",
    "\n",
    "# train[('CA_4','HOBBIES_2')].fillna(method=\"bfill\", inplace=True)\n",
    "print(train.isna().any())\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa378fd5",
   "metadata": {},
   "source": [
    "We can indeed confirm that we have 70 series (columns). Each corresponding to a combination of store and department id. The next step is to tune a model for each of the series. To do so, we enrich our data further by adding exogenous columns. These are features that indicate calendar dates, specifically, the day, week, month, and year--as well as indicators for events (holidays) and sales promotions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40ab2a",
   "metadata": {},
   "source": [
    "## Prepare Exogenous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2469d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:07.295989Z",
     "start_time": "2022-01-03T23:54:45.264453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price    dept_id   cat_id\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58  HOBBIES_1  HOBBIES\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58  HOBBIES_1  HOBBIES\n",
       "2     CA_1  HOBBIES_1_001     11327        8.26  HOBBIES_1  HOBBIES\n",
       "3     CA_1  HOBBIES_1_001     11328        8.26  HOBBIES_1  HOBBIES\n",
       "4     CA_1  HOBBIES_1_001     11329        8.26  HOBBIES_1  HOBBIES"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price exogenous variables\n",
    "prices = pd.read_csv(PATHS.prices_path)\n",
    "prices['dept_id'] = prices['item_id'].str.split(pat='_').apply(lambda row: \"_\".join(row[0:2]))\n",
    "prices['cat_id'] = prices['dept_id'].str.split(pat='_').apply(lambda row: row[0])\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ace8cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.081475Z",
     "start_time": "2022-01-03T23:55:07.297968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sell_price    5.156159\n",
       "Name: 11101, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wk_sell_prices(store_id, dept_id):\n",
    "    \"\"\"Return averege sell prices for series store_id-dept_id\"\"\"\n",
    "    return (prices.loc[(prices['store_id']==store_id) & \\\n",
    "                      (prices['dept_id']==dept_id), :]\n",
    "          .groupby('wm_yr_wk')\n",
    "          .mean())\n",
    "\n",
    "def map_wk_to_price(wk_sell_prices, wm_yr_wk):\n",
    "    \"\"\"Return average sell price from wk_sell_prices for a wm_yr_wk\"\"\"\n",
    "    return wk_sell_prices.loc[wm_yr_wk]\n",
    "\n",
    "# test functions, store_id, dept_id, and wm_yr_wk should map to sell price\n",
    "map_wk_to_price(get_wk_sell_prices('WI_1', 'HOUSEHOLD_1'), 11101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93ee7a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.188745Z",
     "start_time": "2022-01-03T23:55:09.083357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultural     37\n",
      "National     52\n",
      "Religious    55\n",
      "Sporting     18\n",
      "dtype: int64\n",
      "Shape:  (1941, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# calendar, promotions, and holiday events indicator\n",
    "calendar = pd.read_csv(PATHS.calendar_path)\n",
    "\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar.set_index('date', inplace=True)\n",
    "\n",
    "# include wm_yr_wk to map sell prices (exogenous, numerical)\n",
    "exo_cols = ['wm_yr_wk', 'wday', 'month', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "exo = calendar[exo_cols]\n",
    "\n",
    "# Transform to zero-based\n",
    "exo['wday'] = exo['wday'].subtract(1) \n",
    "exo['month'] = exo['month'].subtract(1)\n",
    "\n",
    "events = pd.get_dummies(calendar[['event_type_1', 'event_type_2']], \n",
    "                        columns=['event_type_1', 'event_type_2'])\n",
    "event_types = ['Cultural', 'National', 'Religious', 'Sporting']\n",
    "events_OHE = pd.DataFrame()\n",
    "for event in event_types:\n",
    "    try:\n",
    "        events_OHE[event] = int(bool(events[f'event_type_1_{event}'] + \\\n",
    "        events[f'event_type_2_{event}']))\n",
    "    except:\n",
    "        events_OHE[event] = events[f'event_type_1_{event}']\n",
    "        \n",
    "events = events_OHE\n",
    "# Sanity Check\n",
    "print(events.sum())\n",
    "\n",
    "# Exogenous Data\n",
    "exo = exo.merge(events, on='date')\n",
    "exo = exo.iloc[0:-28] # Remove excess rows (only used in actual M5)\n",
    "\n",
    "exo.head(3)\n",
    "print(\"Shape: \", exo.shape) # confirm length of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01af7761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.262742Z",
     "start_time": "2022-01-03T23:55:09.190476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/pandas/core/frame.py:9203: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left,1 on the right)\n",
      "  validate=validate,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(CA_1, FOODS_1)</th>\n",
       "      <th>(CA_1, FOODS_2)</th>\n",
       "      <th>(CA_1, FOODS_3)</th>\n",
       "      <th>(CA_1, HOBBIES_1)</th>\n",
       "      <th>(CA_1, HOBBIES_2)</th>\n",
       "      <th>(CA_1, HOUSEHOLD_1)</th>\n",
       "      <th>(CA_1, HOUSEHOLD_2)</th>\n",
       "      <th>(CA_2, FOODS_1)</th>\n",
       "      <th>(CA_2, FOODS_2)</th>\n",
       "      <th>(CA_2, FOODS_3)</th>\n",
       "      <th>...</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>Cultural</th>\n",
       "      <th>National</th>\n",
       "      <th>Religious</th>\n",
       "      <th>Sporting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>297.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>284.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>214.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            (CA_1, FOODS_1)  (CA_1, FOODS_2)  (CA_1, FOODS_3)  \\\n",
       "date                                                            \n",
       "2011-01-29            297.0            674.0           2268.0   \n",
       "2011-01-30            284.0            655.0           2198.0   \n",
       "2011-01-31            214.0            396.0           1398.0   \n",
       "\n",
       "            (CA_1, HOBBIES_1)  (CA_1, HOBBIES_2)  (CA_1, HOUSEHOLD_1)  \\\n",
       "date                                                                    \n",
       "2011-01-29              528.0               28.0                361.0   \n",
       "2011-01-30              489.0                9.0                350.0   \n",
       "2011-01-31              409.0                6.0                279.0   \n",
       "\n",
       "            (CA_1, HOUSEHOLD_2)  (CA_2, FOODS_1)  (CA_2, FOODS_2)  \\\n",
       "date                                                                \n",
       "2011-01-29                181.0            406.0            212.0   \n",
       "2011-01-30                170.0            408.0            227.0   \n",
       "2011-01-31                114.0            238.0            138.0   \n",
       "\n",
       "            (CA_2, FOODS_3)  ...  wm_yr_wk  wday  month  snap_CA  snap_TX  \\\n",
       "date                         ...                                            \n",
       "2011-01-29           1575.0  ...     11101     0      0        0        0   \n",
       "2011-01-30           1286.0  ...     11101     1      0        0        0   \n",
       "2011-01-31            913.0  ...     11101     2      0        0        0   \n",
       "\n",
       "            snap_WI  Cultural  National  Religious  Sporting  \n",
       "date                                                          \n",
       "2011-01-29        0         0         0          0         0  \n",
       "2011-01-30        0         0         0          0         0  \n",
       "2011-01-31        0         0         0          0         0  \n",
       "\n",
       "[3 rows x 80 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restructure index column\n",
    "train.index = exo.index\n",
    "train.head(3)\n",
    "\n",
    "# combine into one frame\n",
    "dataset = train.merge(exo, on='date')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a69a322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.315737Z",
     "start_time": "2022-01-03T23:55:09.290743Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_percentage_error, \n",
    "                             mean_absolute_error, make_scorer, r2_score)\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "from datetime import date\n",
    "\n",
    "%autoreload 2\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfad58a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.349928Z",
     "start_time": "2022-01-03T23:55:09.317782Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='phdinds2024_entry.log', \n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def objective(trial):\n",
    "    # goss params\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'goss',\n",
    "        'metric' : 'rmse',\n",
    "        'seed':11,\n",
    "        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'voting']),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        'learning_rate' : trial.suggest_float(\"learning_rate\", 0.001, 1, log=True),\n",
    "        'num_leaves':  trial.suggest_int('num_leaves', 2, 2**14)\n",
    "    } \n",
    "    top_rate =  trial.suggest_float(\"top_rate\", 0, 1.0)\n",
    "    other_rate = trial.suggest_float(\"other_rate\", 0, (1.0 - top_rate)*0.90) \n",
    "    \n",
    "    # corrects the top_rate/other_rate values to only sum to 1\n",
    "    if (top_rate + other_rate) > 1.0:\n",
    "        lgb_params['other_rate'] = other_rate / (top_rate + other_rate)\n",
    "        lgb_params['top_rate'] = top_rate / (top_rate + other_rate)\n",
    "\n",
    "    other_params = {\n",
    "        'lookback_endo' : trial.suggest_categorical('lookback_endo', [False, True]), \n",
    "        'lookback_exo_num': trial.suggest_categorical('lookback_exo_num', [False, True]), \n",
    "        'lookahead_exo_num': trial.suggest_categorical('lookahead_exo_num', [False, True]), \n",
    "        'lookback_exo_cat': trial.suggest_categorical('lookback_exo_cat', [False, True]),\n",
    "        'lookahead_exo_cat': trial.suggest_categorical('lookahead_exo_cat', [False, True]), \n",
    "        'lookback' : trial.suggest_int('lookback', 1, 12),\n",
    "        'delay': trial.suggest_int('delay', 0, 12)\n",
    "    }\n",
    "    \n",
    "    # other create_dataset params\n",
    "    fixed_params = {\n",
    "        'dataset': tuning_data, # change\n",
    "        'exo_cat': exo_cat, # change\n",
    "        'step': step # 28-step forecasts, prediction horizon\n",
    "    }\n",
    "    logging.info(f\"{index + 1}/70 Begin optimization for {endo} \")\n",
    "    logging.info(other_params)\n",
    "    logging.info(lgb_params)\n",
    "    # include this in objective function\n",
    "    X, y, cat_cols_indices =  utils.create_dataset(\n",
    "            endo=endo, exo_num=exo_num, **fixed_params, **other_params)\n",
    "    if X is None:\n",
    "        logging.info(\"create_dataset FAILED\")\n",
    "        return None    \n",
    "    \n",
    "    else:\n",
    "        logging.info(\"create_dataset successful\")\n",
    "        logging.info(f\"Predictors shape: {X.shape} with mem. usage: {X.nbytes}\")\n",
    "        logging.info(f\"Targets shape: {y.shape}\")\n",
    "        logging.info(f\"Cat cols indices: {cat_cols_indices}\")\n",
    "        if len(cat_cols_indices) == 0:\n",
    "            fit_params = None\n",
    "        else:\n",
    "            fit_params = {\n",
    "                'categorical_feature' : cat_cols_indices\n",
    "            }\n",
    "        model = lgb.LGBMRegressor(**lgb_params, verbose=-1)\n",
    "        \n",
    "        # used in selecting which multiout algo to use\n",
    "        mor_algo = trial.suggest_categorical('mor_algo', ['morchain', 'mor'])\n",
    "        \n",
    "        estimators = {\n",
    "            'mor': MultiOutputRegressor(model, n_jobs=-1) ,\n",
    "            'morchain': RegressorChain(model)\n",
    "        }  \n",
    "        estimator = estimators[mor_algo]\n",
    "        logging.info(f\"Estimator {mor_algo}\")\n",
    "        logging.info(f\"Running Cross Validation...\")\n",
    "        \n",
    "        ## repeated kfold cv with rmse as scoring parameter, memory intensive\n",
    "        # rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=11)\n",
    "        \n",
    "        mse_scorer = make_scorer(mean_squared_error)\n",
    "        cv_scores = cross_val_score(estimator=estimator, X=X, y=y, scoring=mse_scorer, \n",
    "                                    cv=3, n_jobs=-1, fit_params=fit_params)\n",
    "        average_rmse = np.mean(np.sqrt(cv_scores))\n",
    "        logging.info(f\"SCORE: {average_rmse}\")\n",
    "        return average_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b25a7e62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.389257Z",
     "start_time": "2022-01-03T23:55:09.353006Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Lifted from winning entry in M5 competition, reduces the size of a dataframe\"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    reduction =  100 * (start_mem - end_mem) / (start_mem)\n",
    "    if verbose: print(f'Mem. usage decreased to {end_mem:5.2f} Mb ({reduction:.1f} % reduction)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "787829dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:09.417711Z",
     "start_time": "2022-01-03T23:55:09.391075Z"
    }
   },
   "outputs": [],
   "source": [
    "# list all 70 series at level 9, store-department level\n",
    "series_list = train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b57def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T09:04:59.566113Z",
     "start_time": "2022-01-03T08:23:55.908386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = str(date.today())\n",
    "for index, series in enumerate(series_list):\n",
    "    n_trials = 2\n",
    "    step = 28\n",
    "    sell_price_arr = get_wk_sell_prices(*series)\n",
    "    tuning_data = dataset.copy()\n",
    "    tuning_data['wk_sell_price'] = tuning_data['wm_yr_wk'].apply(lambda val: map_wk_to_price(sell_price_arr, val))\n",
    "    tuning_data = reduce_mem_usage(tuning_data, verbose=False)\n",
    "    endo = series\n",
    "    exo_num = ['wk_sell_price']\n",
    "    snap_var = 'snap_' + series[0].split('_')[0]\n",
    "    exo_cat = [snap_var, 'wday', 'month', 'Cultural', \n",
    "               'National', 'Religious', 'Sporting']\n",
    "    study_name = f'{series[0]}-{series[1]}'\n",
    "    save_dir = os.path.join(PATHS.tuning, f'{today}-tuning')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    fname = os.path.join(save_dir, f'{study_name}.db')\n",
    "    if os.path.exists(fname):\n",
    "        continue\n",
    "    study = optuna.create_study(direction='minimize', \n",
    "                                study_name=study_name,\n",
    "                                storage=f'sqlite:///{fname}',\n",
    "                                load_if_exists=True)\n",
    "    study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3c2ea",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "In this section, the tuned models are retrained and evaluated. In a **middle-out approach**, we only tuned the models in forecasting `level_id` 9, we then use the forecasts at `level_id` 9 as basis for the other levels. The functions used are  are demonstrated in the `hierarchical_forecasting.ipynb` notebook of this Chapter 8 - Winningest Methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2226306",
   "metadata": {},
   "source": [
    "### Generate Base Forecasts: `level_id` 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc96c526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:49:50.217406Z",
     "start_time": "2022-01-03T23:49:50.178790Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import utils\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63239c2e",
   "metadata": {},
   "source": [
    "#### Rebuild data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96dc0c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T10:29:19.400498Z",
     "start_time": "2022-01-03T10:29:18.892716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_csv(PATHS.calendar_path)\n",
    "\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar.set_index('date', inplace=True)\n",
    "\n",
    "exo_cols = ['wm_yr_wk', 'wday', 'month', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "exo = calendar[exo_cols]\n",
    "\n",
    "# Transform to zero-based\n",
    "exo['wday'] = exo['wday'].subtract(1) \n",
    "exo['month'] = exo['month'].subtract(1)\n",
    "\n",
    "events = pd.get_dummies(calendar[['event_type_1', 'event_type_2']], \n",
    "                        columns=['event_type_1', 'event_type_2'])\n",
    "event_types = ['Cultural', 'National', 'Religious', 'Sporting']\n",
    "events_OHE = pd.DataFrame()\n",
    "for event in event_types:\n",
    "    try:\n",
    "        events_OHE[event] = int(bool(events[f'event_type_1_{event}'] + \\\n",
    "        events[f'event_type_2_{event}']))\n",
    "    except:\n",
    "        events_OHE[event] = events[f'event_type_1_{event}']\n",
    "        \n",
    "events = events_OHE\n",
    "\n",
    "# Exogenous Data\n",
    "exo = exo.merge(events, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609a47b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T10:29:37.579561Z",
     "start_time": "2022-01-03T10:29:32.275184Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(PATHS.test_path)\n",
    "train = pd.read_csv(PATHS.train_path)\n",
    "\n",
    "train = train.groupby(['store_id', 'dept_id']).sum().T\n",
    "train.index = pd.date_range(start='2011-01-29', end='2016-05-22', freq='D')\n",
    "train[train < 5] = np.nan\n",
    "train = train.interpolate(method='linear')\n",
    "# train[('CA_4','HOBBIES_2')].fillna(method=\"bfill\",inplace=True)\n",
    "\n",
    "test = test.groupby(['store_id', 'dept_id']).sum().T\n",
    "\n",
    "dataset = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a76763c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T10:29:37.644642Z",
     "start_time": "2022-01-03T10:29:37.581675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdorosan/.conda-envs/atsa/lib/python3.7/site-packages/pandas/core/frame.py:9203: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left,1 on the right)\n",
      "  validate=validate,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(CA_1, FOODS_1)</th>\n",
       "      <th>(CA_1, FOODS_2)</th>\n",
       "      <th>(CA_1, FOODS_3)</th>\n",
       "      <th>(CA_1, HOBBIES_1)</th>\n",
       "      <th>(CA_1, HOBBIES_2)</th>\n",
       "      <th>(CA_1, HOUSEHOLD_1)</th>\n",
       "      <th>(CA_1, HOUSEHOLD_2)</th>\n",
       "      <th>(CA_2, FOODS_1)</th>\n",
       "      <th>(CA_2, FOODS_2)</th>\n",
       "      <th>(CA_2, FOODS_3)</th>\n",
       "      <th>...</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>Cultural</th>\n",
       "      <th>National</th>\n",
       "      <th>Religious</th>\n",
       "      <th>Sporting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>297.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>284.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>214.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            (CA_1, FOODS_1)  (CA_1, FOODS_2)  (CA_1, FOODS_3)  \\\n",
       "date                                                            \n",
       "2011-01-29            297.0            674.0           2268.0   \n",
       "2011-01-30            284.0            655.0           2198.0   \n",
       "2011-01-31            214.0            396.0           1398.0   \n",
       "\n",
       "            (CA_1, HOBBIES_1)  (CA_1, HOBBIES_2)  (CA_1, HOUSEHOLD_1)  \\\n",
       "date                                                                    \n",
       "2011-01-29              528.0               28.0                361.0   \n",
       "2011-01-30              489.0                9.0                350.0   \n",
       "2011-01-31              409.0                6.0                279.0   \n",
       "\n",
       "            (CA_1, HOUSEHOLD_2)  (CA_2, FOODS_1)  (CA_2, FOODS_2)  \\\n",
       "date                                                                \n",
       "2011-01-29                181.0            406.0            212.0   \n",
       "2011-01-30                170.0            408.0            227.0   \n",
       "2011-01-31                114.0            238.0            138.0   \n",
       "\n",
       "            (CA_2, FOODS_3)  ...  wm_yr_wk  wday  month  snap_CA  snap_TX  \\\n",
       "date                         ...                                            \n",
       "2011-01-29           1575.0  ...     11101     0      0        0        0   \n",
       "2011-01-30           1286.0  ...     11101     1      0        0        0   \n",
       "2011-01-31            913.0  ...     11101     2      0        0        0   \n",
       "\n",
       "            snap_WI  Cultural  National  Religious  Sporting  \n",
       "date                                                          \n",
       "2011-01-29        0         0         0          0         0  \n",
       "2011-01-30        0         0         0          0         0  \n",
       "2011-01-31        0         0         0          0         0  \n",
       "\n",
       "[3 rows x 80 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index = exo.index\n",
    "dataset = dataset.merge(exo, on='date')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d0dc0",
   "metadata": {},
   "source": [
    "#### Retrain using best hyparparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edee671d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T10:29:37.675085Z",
     "start_time": "2022-01-03T10:29:37.646335Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lgb_params(params):\n",
    "    \"\"\"Return lgb params from best parameter dict\"\"\"\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'goss',\n",
    "        'metric' : 'rmse',\n",
    "        'seed':11,\n",
    "        'tree_learner': params['tree_learner'],\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'learning_rate' : params['learning_rate'],\n",
    "        'num_leaves':  params['num_leaves']\n",
    "    } \n",
    "    # corrects the top_rate/other_rate values to only sum to 1\n",
    "    other_rate = params['other_rate']\n",
    "    top_rate = params['top_rate']\n",
    "    if (top_rate + other_rate) > 1.0:\n",
    "        lgb_params['other_rate'] = other_rate / (top_rate + other_rate)\n",
    "        lgb_params['top_rate']  = top_rate / (top_rate + other_rate)\n",
    "\n",
    "    return lgb_params\n",
    "\n",
    "def get_other_params(params):\n",
    "    \"\"\"Return other params from best parameter dict\"\"\"\n",
    "    other_params = {\n",
    "        'lookback_endo' : params['lookback_endo'], \n",
    "        'lookback_exo_num': params['lookback_exo_num'], \n",
    "        'lookahead_exo_num': params['lookahead_exo_num'], \n",
    "        'lookback_exo_cat': params['lookback_exo_cat'],\n",
    "        'lookahead_exo_cat': params['lookahead_exo_cat'], \n",
    "        'lookback' : params['lookback'],\n",
    "        'delay': params['delay']\n",
    "    }\n",
    "    return other_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712fbb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T21:20:58.696283Z",
     "start_time": "2022-01-03T10:53:35.029052Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize predictions dataframe : level 9\n",
    "level9_forecasts = pd.DataFrame(index=dataset.iloc[-28:,:].index, \n",
    "                                columns=dataset.columns)\n",
    "logging.basicConfig(filename='phdinds2024_entry.log', level=logging.INFO)\n",
    "\n",
    "day = \"2022-01-03\" # change date\n",
    "for index, series in enumerate(series_list):\n",
    "    logging.info(\"================================\")\n",
    "    logging.info(f\"Begin {series} : {index + 1}/70\")\n",
    "    # init input params\n",
    "    step = 28\n",
    "    endo = series\n",
    "    exo_num = ['wk_sell_price']\n",
    "    snap_var = 'snap_' + series[0].split('_')[0]\n",
    "    exo_cat = [snap_var, 'wday', 'month', 'Cultural', \n",
    "            'National', 'Religious', 'Sporting']\n",
    "\n",
    "    # create sell prices column\n",
    "    sell_price_arr = get_wk_sell_prices(*series)\n",
    "    temp_data = dataset.copy()\n",
    "    temp_data['wk_sell_price'] = temp_data['wm_yr_wk'].apply(lambda val: map_wk_to_price(sell_price_arr, val))\n",
    "    temp_data = reduce_mem_usage(temp_data)\n",
    "\n",
    "    # retrieve study data\n",
    "    study_name = f'{series[0]}-{series[1]}'\n",
    "    save_dir = os.path.join(PATHS.tuning, f'{day}-tuning')\n",
    "    fname = os.path.join(save_dir, f'{study_name}.db')\n",
    "    print(fname)\n",
    "    study = optuna.load_study(study_name=study_name,\n",
    "                              storage=f'sqlite:///{fname}')\n",
    "    logging.info(f\"Load {study_name} study SUCCESS\")\n",
    "\n",
    "    # get best params\n",
    "    params = study.best_params\n",
    "    lgb_params = get_lgb_params(params)\n",
    "    other_params = get_other_params(params)\n",
    "\n",
    "    # split\n",
    "    holdout_data = temp_data[-(step + other_params['lookback'] + other_params['delay']):]\n",
    "    train_data = temp_data[:-step]\n",
    "\n",
    "    # other create_dataset params\n",
    "    fixed_params = {\n",
    "        'endo': endo, \n",
    "        'exo_cat': exo_cat,\n",
    "        'exo_num': exo_num,\n",
    "        'step': step # 28-step forecasts, prediction horizon\n",
    "    }\n",
    "\n",
    "    train_X, train_y, train_cat_cols = utils.create_dataset(\n",
    "        dataset=train_data, **fixed_params, **other_params)\n",
    "    logging.info(\"Create train_data SUCCESS\")\n",
    "    logging.info(f\"Train input shape: {train_X.shape}\")\n",
    "    holdout_X, holdout_y, holdout_cat_cols = utils.create_dataset(\n",
    "        dataset=holdout_data, **fixed_params, **other_params)\n",
    "    logging.info(\"Create holdout_data SUCCESS\")\n",
    "    logging.info(f\"Holdout input shape: {holdout_X.shape}\")\n",
    "\n",
    "    fit_params = {\n",
    "        'categorical_feature' : train_cat_cols\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**lgb_params, verbose=-1)\n",
    "    estimators = {\n",
    "        'mor': MultiOutputRegressor(model, n_jobs=-1) ,\n",
    "        'morchain': RegressorChain(model)\n",
    "    }  \n",
    "    estimator = estimators[params['mor_algo']]\n",
    "\n",
    "    # fit\n",
    "    logging.info(f\"Fitting...\")\n",
    "    trained_est = estimator.fit(train_X, train_y, **fit_params)\n",
    "\n",
    "    # save\n",
    "    if not os.path.exists(PATHS.trained_models):\n",
    "        os.makedirs(PATHS.trained_models)\n",
    "    model_path = os.path.join(PATHS.trained_models, f\"{study_name}.joblib\")\n",
    "    joblib.dump(trained_est, model_path) \n",
    "\n",
    "    # trained_est = load(model_path) # load \n",
    "\n",
    "    # predict\n",
    "    logging.info(f\"Generating Forecast...\")\n",
    "    y_pred = trained_est.predict(holdout_X)\n",
    "    \n",
    "    # round-off to whole number, forecasted unit sales\n",
    "    level9_forecasts[series] = np.round(y_pred[0]).astype(int)\n",
    "    logging.info(f\"Retrain-Predict {series} SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15f14172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:33:20.507859Z",
     "start_time": "2022-01-03T23:33:20.329664Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_path = os.path.join(PATHS.predictions, '9.csv')\n",
    "level9_forecasts[series_list].to_csv(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413698af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:51:38.495556Z",
     "start_time": "2022-01-03T23:51:38.270647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>d_1942</th>\n",
       "      <th>d_1943</th>\n",
       "      <th>d_1944</th>\n",
       "      <th>d_1945</th>\n",
       "      <th>d_1946</th>\n",
       "      <th>d_1947</th>\n",
       "      <th>d_1948</th>\n",
       "      <th>d_1949</th>\n",
       "      <th>d_1950</th>\n",
       "      <th>d_1951</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1960</th>\n",
       "      <th>d_1961</th>\n",
       "      <th>d_1962</th>\n",
       "      <th>d_1963</th>\n",
       "      <th>d_1964</th>\n",
       "      <th>d_1965</th>\n",
       "      <th>d_1966</th>\n",
       "      <th>d_1967</th>\n",
       "      <th>d_1968</th>\n",
       "      <th>d_1969</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">CA</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">CA_1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">HOBBIES</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">HOBBIES_1</th>\n",
       "      <th>HOBBIES_1_001</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   d_1942  d_1943  d_1944  \\\n",
       "state_id store_id cat_id  dept_id   item_id                                 \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       2       0       1   \n",
       "                                    HOBBIES_1_002       0       2       0   \n",
       "                                    HOBBIES_1_003       0       0       0   \n",
       "\n",
       "                                                   d_1945  d_1946  d_1947  \\\n",
       "state_id store_id cat_id  dept_id   item_id                                 \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       0       0       1   \n",
       "                                    HOBBIES_1_002       1       0       1   \n",
       "                                    HOBBIES_1_003       0       0       1   \n",
       "\n",
       "                                                   d_1948  d_1949  d_1950  \\\n",
       "state_id store_id cat_id  dept_id   item_id                                 \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       4       3       0   \n",
       "                                    HOBBIES_1_002       0       1       0   \n",
       "                                    HOBBIES_1_003       0       0       0   \n",
       "\n",
       "                                                   d_1951  ...  d_1960  \\\n",
       "state_id store_id cat_id  dept_id   item_id                ...           \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       0  ...       2   \n",
       "                                    HOBBIES_1_002       0  ...       1   \n",
       "                                    HOBBIES_1_003       0  ...       1   \n",
       "\n",
       "                                                   d_1961  d_1962  d_1963  \\\n",
       "state_id store_id cat_id  dept_id   item_id                                 \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       1       2       0   \n",
       "                                    HOBBIES_1_002       0       0       1   \n",
       "                                    HOBBIES_1_003       3       2       1   \n",
       "\n",
       "                                                   d_1964  d_1965  d_1966  \\\n",
       "state_id store_id cat_id  dept_id   item_id                                 \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       0       1       0   \n",
       "                                    HOBBIES_1_002       0       0       2   \n",
       "                                    HOBBIES_1_003       0       2       1   \n",
       "\n",
       "                                                   d_1967  d_1968  d_1969  \n",
       "state_id store_id cat_id  dept_id   item_id                                \n",
       "CA       CA_1     HOBBIES HOBBIES_1 HOBBIES_1_001       1       3       1  \n",
       "                                    HOBBIES_1_002       1       1       0  \n",
       "                                    HOBBIES_1_003       0       1       1  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true values\n",
    "true = pd.read_csv(PATHS.test_path)\n",
    "\n",
    "# create multi-index for per level series references\n",
    "item_id = true['item_id']\n",
    "true = true.set_index(['state_id', 'store_id', 'cat_id', 'dept_id', 'item_id'], drop=True)\n",
    "true.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829ad1c",
   "metadata": {},
   "source": [
    "### Bottom Up\n",
    "\n",
    "In this section, we obtain the forecasts for `level_id`s 1 to 8 using a bottom up approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d8d92d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:51:54.277520Z",
     "start_time": "2022-01-03T23:51:54.007081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Level1': None,\n",
       " 'Level2': 'state_id',\n",
       " 'Level3': 'store_id',\n",
       " 'Level4': 'cat_id',\n",
       " 'Level5': 'dept_id',\n",
       " 'Level6': ['state_id', 'cat_id'],\n",
       " 'Level7': ['state_id', 'dept_id'],\n",
       " 'Level8': ['store_id', 'cat_id'],\n",
       " 'Level9': ['store_id', 'dept_id'],\n",
       " 'Level10': ['item_id'],\n",
       " 'Level11': ['state_id', 'item_id'],\n",
       " 'Level12': ['item_id', 'store_id']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_indexes = utils.level_indexes\n",
    "level_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba107bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:55:30.057213Z",
     "start_time": "2022-01-03T23:55:29.978796Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2016-05-23</th>\n",
       "      <th>2016-05-24</th>\n",
       "      <th>2016-05-25</th>\n",
       "      <th>2016-05-26</th>\n",
       "      <th>2016-05-27</th>\n",
       "      <th>2016-05-28</th>\n",
       "      <th>2016-05-29</th>\n",
       "      <th>2016-05-30</th>\n",
       "      <th>2016-05-31</th>\n",
       "      <th>2016-06-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-06-10</th>\n",
       "      <th>2016-06-11</th>\n",
       "      <th>2016-06-12</th>\n",
       "      <th>2016-06-13</th>\n",
       "      <th>2016-06-14</th>\n",
       "      <th>2016-06-15</th>\n",
       "      <th>2016-06-16</th>\n",
       "      <th>2016-06-17</th>\n",
       "      <th>2016-06-18</th>\n",
       "      <th>2016-06-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">CA</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">CA_1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">FOODS</th>\n",
       "      <th>FOODS_1</th>\n",
       "      <th>HOBBIES_1_001</th>\n",
       "      <td>315</td>\n",
       "      <td>292</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>431</td>\n",
       "      <td>462</td>\n",
       "      <td>413</td>\n",
       "      <td>336</td>\n",
       "      <td>361</td>\n",
       "      <td>361</td>\n",
       "      <td>...</td>\n",
       "      <td>424</td>\n",
       "      <td>462</td>\n",
       "      <td>397</td>\n",
       "      <td>348</td>\n",
       "      <td>321</td>\n",
       "      <td>362</td>\n",
       "      <td>364</td>\n",
       "      <td>459</td>\n",
       "      <td>482</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2</th>\n",
       "      <th>HOBBIES_1_002</th>\n",
       "      <td>443</td>\n",
       "      <td>335</td>\n",
       "      <td>351</td>\n",
       "      <td>431</td>\n",
       "      <td>509</td>\n",
       "      <td>502</td>\n",
       "      <td>558</td>\n",
       "      <td>508</td>\n",
       "      <td>519</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>515</td>\n",
       "      <td>636</td>\n",
       "      <td>675</td>\n",
       "      <td>499</td>\n",
       "      <td>474</td>\n",
       "      <td>461</td>\n",
       "      <td>371</td>\n",
       "      <td>438</td>\n",
       "      <td>629</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3</th>\n",
       "      <th>HOBBIES_1_003</th>\n",
       "      <td>1850</td>\n",
       "      <td>1835</td>\n",
       "      <td>1833</td>\n",
       "      <td>1894</td>\n",
       "      <td>2283</td>\n",
       "      <td>2602</td>\n",
       "      <td>2388</td>\n",
       "      <td>1944</td>\n",
       "      <td>1786</td>\n",
       "      <td>1748</td>\n",
       "      <td>...</td>\n",
       "      <td>2047</td>\n",
       "      <td>2544</td>\n",
       "      <td>2612</td>\n",
       "      <td>1877</td>\n",
       "      <td>1655</td>\n",
       "      <td>1654</td>\n",
       "      <td>1748</td>\n",
       "      <td>2144</td>\n",
       "      <td>2655</td>\n",
       "      <td>2747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                                            2016-05-23  2016-05-24  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         315         292   \n",
       "                         FOODS_2 HOBBIES_1_002         443         335   \n",
       "                         FOODS_3 HOBBIES_1_003        1850        1835   \n",
       "\n",
       "date                                            2016-05-25  2016-05-26  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         337         337   \n",
       "                         FOODS_2 HOBBIES_1_002         351         431   \n",
       "                         FOODS_3 HOBBIES_1_003        1833        1894   \n",
       "\n",
       "date                                            2016-05-27  2016-05-28  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         431         462   \n",
       "                         FOODS_2 HOBBIES_1_002         509         502   \n",
       "                         FOODS_3 HOBBIES_1_003        2283        2602   \n",
       "\n",
       "date                                            2016-05-29  2016-05-30  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         413         336   \n",
       "                         FOODS_2 HOBBIES_1_002         558         508   \n",
       "                         FOODS_3 HOBBIES_1_003        2388        1944   \n",
       "\n",
       "date                                            2016-05-31  2016-06-01  ...  \\\n",
       "state_id store_id cat_id dept_id item_id                                ...   \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         361         361  ...   \n",
       "                         FOODS_2 HOBBIES_1_002         519         487  ...   \n",
       "                         FOODS_3 HOBBIES_1_003        1786        1748  ...   \n",
       "\n",
       "date                                            2016-06-10  2016-06-11  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         424         462   \n",
       "                         FOODS_2 HOBBIES_1_002         515         636   \n",
       "                         FOODS_3 HOBBIES_1_003        2047        2544   \n",
       "\n",
       "date                                            2016-06-12  2016-06-13  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         397         348   \n",
       "                         FOODS_2 HOBBIES_1_002         675         499   \n",
       "                         FOODS_3 HOBBIES_1_003        2612        1877   \n",
       "\n",
       "date                                            2016-06-14  2016-06-15  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         321         362   \n",
       "                         FOODS_2 HOBBIES_1_002         474         461   \n",
       "                         FOODS_3 HOBBIES_1_003        1655        1654   \n",
       "\n",
       "date                                            2016-06-16  2016-06-17  \\\n",
       "state_id store_id cat_id dept_id item_id                                 \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         364         459   \n",
       "                         FOODS_2 HOBBIES_1_002         371         438   \n",
       "                         FOODS_3 HOBBIES_1_003        1748        2144   \n",
       "\n",
       "date                                            2016-06-18  2016-06-19  \n",
       "state_id store_id cat_id dept_id item_id                                \n",
       "CA       CA_1     FOODS  FOODS_1 HOBBIES_1_001         482         396  \n",
       "                         FOODS_2 HOBBIES_1_002         629         550  \n",
       "                         FOODS_3 HOBBIES_1_003        2655        2747  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restructure base forecacst (level 9) dataframe\n",
    "preds_path = os.path.join(PATHS.predictions, '9.csv')\n",
    "level9_forecasts = pd.read_csv(preds_path, index_col='date')\n",
    "m_index = pd.MultiIndex.from_tuples(series_list, \n",
    "                                    names=['store_id', 'dept_id'])\n",
    "level9_forecasts = level9_forecasts.T.reset_index(drop=True)\n",
    "level9_forecasts.index = m_index\n",
    "\n",
    "# state_id and cat_id indexes\n",
    "state_id = [i[0].split('_')[0] for i in level9_forecasts.index]\n",
    "cat_id = [i[1].split('_')[0] for i in level9_forecasts.index]\n",
    "\n",
    "# create new multi-index for per level series references\n",
    "level9_forecasts = level9_forecasts.reset_index()\n",
    "level9_forecasts['state_id'] = state_id\n",
    "level9_forecasts['cat_id'] = cat_id\n",
    "level9_forecasts['item_id'] = item_id\n",
    "level9_forecasts.set_index(['state_id', 'store_id', 'cat_id', 'dept_id', 'item_id'], inplace=True, drop=True)\n",
    "level9_forecasts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b1ae923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:56:09.965809Z",
     "start_time": "2022-01-03T23:56:09.587122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Dollar_Sales</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_id</th>\n",
       "      <th>Agg_Level_1</th>\n",
       "      <th>Agg_Level_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Level12</th>\n",
       "      <th>HOBBIES_1_001</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>276.54</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>27.79</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>62.37</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_004</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>227.36</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_005</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>112.32</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_006</th>\n",
       "      <th>CA_1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Dollar_Sales    weight\n",
       "Level_id Agg_Level_1   Agg_Level_2                        \n",
       "Level12  HOBBIES_1_001 CA_1               276.54  0.000071\n",
       "         HOBBIES_1_002 CA_1                27.79  0.000007\n",
       "         HOBBIES_1_003 CA_1                62.37  0.000016\n",
       "         HOBBIES_1_004 CA_1               227.36  0.000058\n",
       "         HOBBIES_1_005 CA_1               112.32  0.000029\n",
       "         HOBBIES_1_006 CA_1                28.80  0.000007"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reference file for per series/level weight used in WRMSSE\n",
    "weights_df = pd.read_csv(PATHS.weights_eval_path)\n",
    "weights_df = weights_df.set_index(['Level_id', 'Agg_Level_1', 'Agg_Level_2'], drop=True)\n",
    "weights_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee1137cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:56:19.503871Z",
     "start_time": "2022-01-03T23:56:15.035562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id    dept_id   cat_id store_id state_id  d_1  d_2  d_3  d_4  \\\n",
       "0  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "2  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0   \n",
       "\n",
       "   d_5  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  d_1939  \\\n",
       "0    0  ...       2       4       0       0       0       0       3       3   \n",
       "1    0  ...       0       1       2       1       1       0       0       0   \n",
       "2    0  ...       1       0       2       0       0       0       2       3   \n",
       "\n",
       "   d_1940  d_1941  \n",
       "0       0       1  \n",
       "1       0       0  \n",
       "2       0       1  \n",
       "\n",
       "[3 rows x 1946 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize rmsse function: per series rmsse calculation\n",
    "def rmsse(y_true, y_pred, ts):\n",
    "    \"\"\"Return the root-mean-squred error scaled according to reference\n",
    "    series, ts\"\"\"\n",
    "    y_true = y_true.values\n",
    "    y_pred = y_pred.values\n",
    "    score = np.sqrt(np.mean((y_true - y_pred)**2)/ np.mean((ts[1:] - ts[:-1])**2))\n",
    "    return score\n",
    "\n",
    "# use original train series per level as rmsse reference, ts\n",
    "rmsse_ref = pd.read_csv(PATHS.train_path)\n",
    "rmsse_ref.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec9caa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T23:56:36.840612Z",
     "start_time": "2022-01-03T23:56:36.801973Z"
    }
   },
   "outputs": [],
   "source": [
    "def scorer(row, forecasts, ts, weights_df, level):\n",
    "    \"\"\"Return weighted rmsse score for a series (row)\n",
    "    \"\"\"\n",
    "    temp_ts = ts.loc[row.name]\n",
    "    temp_ts = temp_ts.values\n",
    "    \n",
    "    raw = rmsse(row, forecasts.loc[row.name], temp_ts)\n",
    "    \n",
    "    if type(row.name) is tuple:\n",
    "        location = (level, row.name[0], row.name[1])\n",
    "    else:\n",
    "        location = (level, row.name, 'X')\n",
    "    weight = weights_df.loc[location]['weight']\n",
    "    weighted = raw * weight\n",
    "    return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0473983b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:51:53.771672Z",
     "start_time": "2022-01-04T00:51:44.233327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Level1': 0.5502233780150557, 'Level2': 0.6426648399137538, 'Level3': 0.8393486287733846, 'Level4': 0.6469301659242289, 'Level5': 0.7206268952304807, 'Level6': 0.7083074749749858, 'Level7': 0.7980672932751173, 'Level8': 0.9000055527093302}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "level_bu = list(level_indexes.keys())[0:8]\n",
    "\n",
    "WRMSSE = {}\n",
    "for level in tqdm(level_bu):\n",
    "    forecasts = utils.generate_bu(level, level9_forecasts, level_indexes)\n",
    "    index = level_indexes[level]\n",
    "    if index:\n",
    "        actual = true.groupby(index).sum()\n",
    "        ts = rmsse_ref.groupby(index).sum()\n",
    "        scores = actual.apply(lambda row: scorer(row, forecasts, ts, weights_df, level), axis=1)\n",
    "        WRMSSE[level] = scores.sum()\n",
    "    else:\n",
    "        actual = true.sum()\n",
    "        ts = rmsse_ref.groupby(['item_id','dept_id','cat_id','store_id', 'state_id']).sum()\n",
    "        ts = ts.sum()\n",
    "        raw = rmsse(forecasts, actual, ts.values)\n",
    "        weight = weights_df.loc[(level, 'Total', 'X')]['weight']\n",
    "        WRMSSE[level] = raw*weight\n",
    "print(WRMSSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e73193",
   "metadata": {},
   "source": [
    "### Top Down\n",
    "\n",
    "Now, we have obtained the forecasts for levels 1 to 9. We now obtain the forecasts in the lower/finer levels in the hierarchy (ie. higher level ids, `level_id`s 10 to 12). To do so, we perform a top-down approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40810f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:52:34.856957Z",
     "start_time": "2022-01-04T00:52:34.657162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1886</th>\n",
       "      <th>d_1887</th>\n",
       "      <th>d_1888</th>\n",
       "      <th>d_1889</th>\n",
       "      <th>d_1890</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id    dept_id   cat_id store_id state_id  d_1886  d_1887  \\\n",
       "0  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA       1       0   \n",
       "1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA       1       0   \n",
       "2  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA       0       0   \n",
       "\n",
       "   d_1888  d_1889  d_1890  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       0       0       0  ...       1       3       0       1       1   \n",
       "1       0       0       0  ...       0       0       0       0       0   \n",
       "2       0       0       0  ...       2       1       2       1       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get proportions, proportions_reference.csv from heirarchical_forecasting\n",
    "prop_reference = pd.read_csv(PATHS.proportions_reference) \n",
    "prop_reference.set_index(['state_id', 'store_id', 'item_id', 'dept_id', 'cat_id'])\n",
    "prop_reference.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf5227b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:54:36.544407Z",
     "start_time": "2022-01-04T00:53:39.982927Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:56<00:00, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Level1': 0.5502233780150557, 'Level2': 0.6426648399137538, 'Level3': 0.8393486287733846, 'Level4': 0.6469301659242289, 'Level5': 0.7206268952304807, 'Level6': 0.7083074749749858, 'Level7': 0.7980672932751173, 'Level8': 0.9000055527093302, 'Level10': 1.2742673980400276, 'Level11': 1.1900034946181992, 'Level12': 1.141116451190625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "level_td = list(level_indexes.keys())[9:]\n",
    "\n",
    "for level in tqdm(level_td):\n",
    "    forecasts = utils.generate_td(level, level9_forecasts, utils.get_ave_proportions,\n",
    "                                  level_indexes=level_indexes,\n",
    "                                  prop_reference=prop_reference, T=28)\n",
    "    index = level_indexes[level]\n",
    "    if index:\n",
    "        actual = true.groupby(index).sum()\n",
    "        ts = rmsse_ref.groupby(index).sum()\n",
    "        scores = actual.apply(lambda row: scorer(row, forecasts, ts, weights_df, level), axis=1)\n",
    "        WRMSSE[level] = scores.sum()\n",
    "    else:\n",
    "        actual = true.sum()\n",
    "        ts = rmsse_ref.groupby(['item_id','dept_id','cat_id','store_id', 'state_id']).sum()\n",
    "        ts = ts.sum()\n",
    "        raw = rmsse(forecasts, actual, ts.values)\n",
    "        weight = weights_df.loc[(level, 'Total', 'X')]['weight']\n",
    "        WRMSSE[level] = raw * weight\n",
    "print(WRMSSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83b3f6cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:54:39.808205Z",
     "start_time": "2022-01-04T00:54:38.919891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 9 MOR WRMSSE:  0.9789536681679601\n",
      "{'Level1': 0.5502233780150557, 'Level2': 0.6426648399137538, 'Level3': 0.8393486287733846, 'Level4': 0.6469301659242289, 'Level5': 0.7206268952304807, 'Level6': 0.7083074749749858, 'Level7': 0.7980672932751173, 'Level8': 0.9000055527093302, 'Level10': 1.2742673980400276, 'Level11': 1.1900034946181992, 'Level12': 1.141116451190625, 'Level9': 0.9789536681679601}\n"
     ]
    }
   ],
   "source": [
    "# level9 scores\n",
    "index = ['store_id', 'dept_id'] # level9\n",
    "forecasts = level9_forecasts.groupby(index).sum()\n",
    "actual = true.groupby(index).sum()\n",
    "ts = rmsse_ref.groupby(index).sum()\n",
    "scores = actual.apply(lambda row: scorer(row, forecasts, ts, weights_df, 'Level9'), axis=1)\n",
    "print('Level 9 MOR WRMSSE: ', scores.sum())\n",
    "WRMSSE['Level9'] = scores.sum()\n",
    "print(WRMSSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbe3679d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T01:50:54.869579Z",
     "start_time": "2022-01-04T01:50:54.808293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level1</th>\n",
       "      <th>Level2</th>\n",
       "      <th>Level3</th>\n",
       "      <th>Level4</th>\n",
       "      <th>Level5</th>\n",
       "      <th>Level6</th>\n",
       "      <th>Level7</th>\n",
       "      <th>Level8</th>\n",
       "      <th>Level10</th>\n",
       "      <th>Level11</th>\n",
       "      <th>Level12</th>\n",
       "      <th>Level9</th>\n",
       "      <th>AveWRMSSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phdinds2024</th>\n",
       "      <td>0.550223</td>\n",
       "      <td>0.642665</td>\n",
       "      <td>0.839349</td>\n",
       "      <td>0.64693</td>\n",
       "      <td>0.720627</td>\n",
       "      <td>0.708307</td>\n",
       "      <td>0.798067</td>\n",
       "      <td>0.900006</td>\n",
       "      <td>1.274267</td>\n",
       "      <td>1.190003</td>\n",
       "      <td>1.141116</td>\n",
       "      <td>0.978954</td>\n",
       "      <td>0.865876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Level1    Level2    Level3   Level4    Level5    Level6  \\\n",
       "Entry                                                                    \n",
       "phdinds2024  0.550223  0.642665  0.839349  0.64693  0.720627  0.708307   \n",
       "\n",
       "               Level7    Level8   Level10   Level11   Level12    Level9  \\\n",
       "Entry                                                                     \n",
       "phdinds2024  0.798067  0.900006  1.274267  1.190003  1.141116  0.978954   \n",
       "\n",
       "             AveWRMSSE  \n",
       "Entry                   \n",
       "phdinds2024   0.865876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WRMSSE_new = {k: [v] for k,v in WRMSSE.items()}\n",
    "res = pd.DataFrame.from_dict(WRMSSE_new)\n",
    "res.index = ['phdinds2024'] # entry_name\n",
    "res['AveWRMSSE'] = np.mean(list(WRMSSE.values()))\n",
    "res.index.name = 'Entry'\n",
    "\n",
    "# save\n",
    "res.to_csv('../leaderboards_data/phdinds2024_scores.csv')\n",
    "\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405b532",
   "metadata": {},
   "source": [
    "### Final Score\n",
    "\n",
    "Let's see where we are at. Rank 50 in M5 has an `average WRMSSE` of `0.576`. Also, if we beat the the top performing benchmark which is an Exponential Smoothing method (`0.671`) using the Bottom Up reconciliation approach, we are already at the top 7.5% of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4535cb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T05:20:23.703427Z",
     "start_time": "2022-01-04T05:20:18.379078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave WRMSSE:  0.8658762700694291\n"
     ]
    }
   ],
   "source": [
    "print(\"Ave WRMSSE: \", np.mean(list(WRMSSE.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03674ce",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:atsa]",
   "language": "python",
   "name": "conda-env-atsa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
